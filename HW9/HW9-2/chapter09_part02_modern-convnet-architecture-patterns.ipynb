{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Modern convnet architecture patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Modularity, hierarchy, and reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Residual connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Residual block where the number of filters changes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "residual = x\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "residual = layers.Conv2D(64, 1)(residual)\n",
    "x = layers.add([x, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Case where target block includes a max pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "residual = x\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
    "x = layers.add([x, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 32)   896         ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 32)   9248        ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 32)   128         ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 16, 32)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 64)   18496       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)    0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 64)     2112        ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 8, 8, 64)     0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 128)    73856       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 128)    147584      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 128)    8320        ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 8, 128)    0           ['conv2d_13[0][0]',              \n",
      "                                                                  'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 128)         0           ['add_4[0][0]']                  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            129         ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 297,697\n",
      "Trainable params: 297,697\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "def residual_block(x, filters, pooling=False):\n",
    "    residual = x\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    if pooling:\n",
    "        x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
    "    elif filters != residual.shape[-1]:\n",
    "        residual = layers.Conv2D(filters, 1)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "    return x\n",
    "\n",
    "x = residual_block(x, filters=32, pooling=True)\n",
    "x = residual_block(x, filters=64, pooling=True)\n",
    "x = residual_block(x, filters=128, pooling=False)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Depthwise separable convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Putting it together: A mini Xception-like model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use kaggle's data \"dogs-vs-cats\"(HW8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "original_dir = pathlib.Path(\"dogs-vs-cats/train\")\n",
    "new_base_dir = pathlib.Path(\"dogs-vs-cats/cats_vs_dogs_small\")\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
    "\n",
    "for size in [32, 64, 128, 256, 512]:\n",
    "    residual = x\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    residual = layers.Conv2D(\n",
    "        size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 228s 3s/step - loss: 0.6696 - accuracy: 0.5895 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.6458 - accuracy: 0.6325 - val_loss: 0.6935 - val_accuracy: 0.5150\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 209s 3s/step - loss: 0.6238 - accuracy: 0.6595 - val_loss: 0.7188 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 209s 3s/step - loss: 0.5998 - accuracy: 0.6745 - val_loss: 0.7209 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.5892 - accuracy: 0.6910 - val_loss: 0.7344 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 207s 3s/step - loss: 0.5764 - accuracy: 0.6905 - val_loss: 0.8031 - val_accuracy: 0.5250\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.5534 - accuracy: 0.7200 - val_loss: 0.8636 - val_accuracy: 0.5280\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.5390 - accuracy: 0.7400 - val_loss: 1.1089 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.5369 - accuracy: 0.7365 - val_loss: 0.6481 - val_accuracy: 0.6600\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.5207 - accuracy: 0.7430 - val_loss: 0.6995 - val_accuracy: 0.6120\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.4851 - accuracy: 0.7655 - val_loss: 0.7588 - val_accuracy: 0.6120\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.4851 - accuracy: 0.7755 - val_loss: 0.6379 - val_accuracy: 0.6910\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.4770 - accuracy: 0.7810 - val_loss: 0.9611 - val_accuracy: 0.6180\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.4785 - accuracy: 0.7770 - val_loss: 0.5211 - val_accuracy: 0.7450\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 207s 3s/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.6317 - val_accuracy: 0.6590\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.4563 - accuracy: 0.7930 - val_loss: 0.5871 - val_accuracy: 0.7350\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.4336 - accuracy: 0.7975 - val_loss: 0.6167 - val_accuracy: 0.7150\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 203s 3s/step - loss: 0.4175 - accuracy: 0.8130 - val_loss: 0.5186 - val_accuracy: 0.7710\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.4133 - accuracy: 0.8075 - val_loss: 0.5818 - val_accuracy: 0.7220\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.4028 - accuracy: 0.8160 - val_loss: 0.5201 - val_accuracy: 0.7620\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 203s 3s/step - loss: 0.3850 - accuracy: 0.8310 - val_loss: 0.8064 - val_accuracy: 0.6230\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 203s 3s/step - loss: 0.4013 - accuracy: 0.8240 - val_loss: 1.2708 - val_accuracy: 0.5410\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.3842 - accuracy: 0.8300 - val_loss: 0.4828 - val_accuracy: 0.7790\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 209s 3s/step - loss: 0.3770 - accuracy: 0.8330 - val_loss: 0.4305 - val_accuracy: 0.7920\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 209s 3s/step - loss: 0.3446 - accuracy: 0.8570 - val_loss: 2.0882 - val_accuracy: 0.5230\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 210s 3s/step - loss: 0.3419 - accuracy: 0.8485 - val_loss: 0.4577 - val_accuracy: 0.8040\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.3363 - accuracy: 0.8585 - val_loss: 0.8247 - val_accuracy: 0.7100\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.3176 - accuracy: 0.8660 - val_loss: 1.8358 - val_accuracy: 0.5580\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.3498 - accuracy: 0.8440 - val_loss: 0.4310 - val_accuracy: 0.8140\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.3246 - accuracy: 0.8590 - val_loss: 0.4477 - val_accuracy: 0.8260\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 208s 3s/step - loss: 0.3119 - accuracy: 0.8665 - val_loss: 0.7503 - val_accuracy: 0.7150\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 207s 3s/step - loss: 0.2981 - accuracy: 0.8760 - val_loss: 0.4334 - val_accuracy: 0.8230\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.3131 - accuracy: 0.8685 - val_loss: 0.5127 - val_accuracy: 0.7830\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 203s 3s/step - loss: 0.2967 - accuracy: 0.8730 - val_loss: 0.4859 - val_accuracy: 0.8110\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.2826 - accuracy: 0.8825 - val_loss: 0.4145 - val_accuracy: 0.8310\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.2755 - accuracy: 0.8785 - val_loss: 0.6231 - val_accuracy: 0.7660\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 203s 3s/step - loss: 0.2882 - accuracy: 0.8735 - val_loss: 0.6624 - val_accuracy: 0.7640\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.2633 - accuracy: 0.8945 - val_loss: 0.6560 - val_accuracy: 0.7370\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 207s 3s/step - loss: 0.2815 - accuracy: 0.8825 - val_loss: 0.8648 - val_accuracy: 0.7000\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.2557 - accuracy: 0.8915 - val_loss: 0.4901 - val_accuracy: 0.7940\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 208s 3s/step - loss: 0.2546 - accuracy: 0.8925 - val_loss: 0.4361 - val_accuracy: 0.8240\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.2249 - accuracy: 0.9040 - val_loss: 0.3871 - val_accuracy: 0.8540\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.2424 - accuracy: 0.9020 - val_loss: 0.3481 - val_accuracy: 0.8640\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.2055 - accuracy: 0.9170 - val_loss: 0.9676 - val_accuracy: 0.6740\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.2464 - accuracy: 0.8965 - val_loss: 0.3773 - val_accuracy: 0.8450\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.2132 - accuracy: 0.9095 - val_loss: 0.3711 - val_accuracy: 0.8390\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.2210 - accuracy: 0.9060 - val_loss: 0.4866 - val_accuracy: 0.8220\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 205s 3s/step - loss: 0.2113 - accuracy: 0.9170 - val_loss: 0.3873 - val_accuracy: 0.8510\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.1974 - accuracy: 0.9145 - val_loss: 0.7122 - val_accuracy: 0.7820\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.2150 - accuracy: 0.9125 - val_loss: 0.6370 - val_accuracy: 0.8180\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_dataset)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter09_part02_modern-convnet-architecture-patterns.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "PatternRec",
   "language": "python",
   "name": "patternrec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
